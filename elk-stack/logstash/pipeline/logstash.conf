# ════════════════════════════════════════════════════════════════
# logstash.conf — Logstash Pipeline
#
# A Logstash pipeline has three sections:
#
#   input  → WHERE to read data from (Filebeat, Kafka, S3, stdin, etc.)
#   filter → HOW to parse, enrich, and transform events
#   output → WHERE to send processed events (Elasticsearch, S3, stdout, etc.)
#
# This pipeline:
#   1. Receives log events from Filebeat (Beats protocol on port 5044)
#   2. Detects the log type and parses accordingly:
#        - Apache/Nginx access logs → parsed with the COMBINEDAPACHELOG grok pattern
#        - JSON logs               → parsed with the json filter
#        - Plain text logs         → passed through as-is
#   3. Sends all events to Elasticsearch, indexed by date
# ════════════════════════════════════════════════════════════════


# ── INPUT ─────────────────────────────────────────────────────────
# The 'beats' input plugin listens for connections from Filebeat (and
# other Beats agents). It uses a lightweight binary protocol over TCP.
input {
  beats {
    port => 5044
  }
}


# ── FILTER ────────────────────────────────────────────────────────
# Filters transform events in memory before they are sent to output.
# Multiple filters are applied in order, top to bottom.
filter {

  # ── Apache / Nginx Access Log Parsing ─────────────────────────
  # Filebeat tags access logs with log_type=access (set in filebeat.yml).
  # COMBINEDAPACHELOG is a built-in grok pattern that matches:
  #   IP - - [timestamp] "METHOD /path HTTP/1.1" status bytes "referer" "user-agent"
  if [fields][log_type] == "access" {

    grok {
      match => {
        "message" => "%{COMBINEDAPACHELOG}"
      }
      # If parsing fails, add a _grokparsefailure tag instead of dropping the event
      tag_on_failure => ["_grokparsefailure_access"]
    }

    # Replace the default @timestamp (ingest time) with the actual log timestamp.
    # This ensures time-based queries reflect when the request happened, not when
    # Logstash processed it.
    date {
      match  => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
      remove_field => ["timestamp"]
    }

    # Convert response code and bytes to integers for range queries in Kibana.
    mutate {
      convert => {
        "response" => "integer"
        "bytes"    => "integer"
      }
    }
  }

  # ── JSON Log Parsing ──────────────────────────────────────────
  # Filebeat tags JSON logs with log_type=json (set in filebeat.yml).
  # The json filter parses the 'message' field as JSON and promotes
  # all keys to top-level event fields.
  else if [fields][log_type] == "json" {
    json {
      source => "message"
      # If the JSON has a 'timestamp' field, use it as @timestamp
      target => "parsed"
    }

    # Promote parsed fields to the top level
    ruby {
      code => "
        parsed = event.get('parsed')
        if parsed.is_a?(Hash)
          parsed.each { |k, v| event.set(k, v) }
        end
        event.remove('parsed')
      "
    }
  }

  # ── Cleanup ───────────────────────────────────────────────────
  # Remove Beats metadata fields that add noise to the stored documents.
  # Keeping the index lean improves query performance and storage efficiency.
  mutate {
    remove_field => ["agent", "ecs", "input", "host"]
  }
}


# ── OUTPUT ────────────────────────────────────────────────────────
output {

  # ── Elasticsearch ─────────────────────────────────────────────
  # Send processed events to Elasticsearch.
  # Each log type gets its own index, partitioned by date.
  # Example index names:
  #   logs-access-2024.03.15
  #   logs-json-2024.03.15
  #   logs-app-2024.03.15
  elasticsearch {
    hosts  => ["http://elasticsearch:9200"]
    # Dynamic index name: log type + date
    # Falls back to 'app' if log_type field is not set
    index  => "logs-%{[fields][log_type]:app}-%{+YYYY.MM.dd}"
  }

  # ── stdout ────────────────────────────────────────────────────
  # Print a dot for each processed event to the Logstash container logs.
  # Useful for confirming that events are flowing through the pipeline.
  # Switch to 'rubydebug' codec to see the full event structure (verbose).
  stdout {
    codec => dots
  }
}
